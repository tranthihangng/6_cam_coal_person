"""
Optimized Camera Worker Module
==============================

Worker t·ªëi ∆∞u cho m·ªói camera, d·ª±a tr√™n:
- coal_6cam_v1.py: CameraWorker pattern, atomic updates
- VidGear: Thread management, queue handling
- Multi-Camera-Live-Object-Tracking: Producer-consumer pattern

Key features:
1. Atomic frame update (kh√¥ng queue cho display)
2. Separate queue cho detection
3. Connection status tracking
4. Inference statistics
5. Thread-safe operations
"""

import threading
import time
import queue
import gc
import numpy as np
import cv2
from typing import Optional, Callable, Any, Dict, List, Tuple
from dataclasses import dataclass, field
from enum import Enum

from .inference_stats import get_stats_manager
from ..plc import PLCClient, AlarmManager, AlarmConfig, AlarmType
from ..alerting import AlertLogger, ImageSaver


class WorkerStatus(Enum):
    """Tr·∫°ng th√°i worker"""
    STOPPED = "stopped"
    STARTING = "starting"
    RUNNING = "running"
    RECONNECTING = "reconnecting"
    ERROR = "error"


@dataclass
class WorkerConfig:
    """C·∫•u h√¨nh worker"""
    camera_id: int
    rtsp_url: str
    camera_name: str = ""
    enabled: bool = True
    
    # ROI config
    roi_person: List[Tuple[int, int]] = field(default_factory=list)
    roi_coal: List[Tuple[int, int]] = field(default_factory=list)
    reference_resolution: Tuple[int, int] = (1920, 1080)
    
    # Detection config
    enable_person: bool = True
    enable_coal: bool = True
    person_consecutive_threshold: int = 3
    person_no_detection_threshold: int = 5
    coal_ratio_threshold: float = 73.0
    coal_consecutive_threshold: int = 5
    coal_no_blockage_threshold: int = 5
    detection_confidence: float = 0.7
    
    # PLC config (m·ªói camera c√≥ PLC ri√™ng)
    plc_ip: str = ""
    plc_rack: int = 0
    plc_slot: int = 2
    plc_db_number: int = 300
    plc_person_byte: int = 6
    plc_person_bit: int = 0
    plc_coal_byte: int = 6
    plc_coal_bit: int = 1
    
    # Logging config
    logs_dir: str = "logs"
    artifacts_dir: str = "artifacts"
    
    # Performance config
    target_capture_fps: int = 25
    detection_interval: float = 0.5  # seconds between detection
    buffer_size: int = 1
    enable_grab_pattern: bool = True


class OptimizedCameraWorker:
    """
    Worker t·ªëi ∆∞u cho m·ªôt camera
    
    Features:
    1. Low-latency capture v·ªõi grab pattern
    2. Atomic frame update cho display (kh√¥ng d√πng queue)
    3. Separate queue cho detection
    4. Inference time tracking
    5. ROI-based detection
    6. Automatic reconnection
    
    Usage:
        worker = OptimizedCameraWorker(
            config=WorkerConfig(...),
            model=yolo_model,
            model_lock=threading.Lock(),
            on_alert=lambda cam_id, type, active, val: print(f"Alert: {type}")
        )
        
        worker.start()
        
        # Trong GUI loop:
        frame = worker.get_display_frame()
        if frame is not None:
            display(frame)
        
        # L·∫•y result detection:
        result = worker.get_latest_result()
        
        worker.stop()
    """
    
    # Constants
    MAX_GRAB_COUNT = 3
    MIN_RECONNECT_INTERVAL = 0.5
    MAX_RECONNECT_INTERVAL = 10.0
    
    def __init__(
        self,
        config: WorkerConfig,
        model: Any,
        model_lock: threading.Lock,
        model_id: str = "default",
        on_alert: Optional[Callable[[int, str, bool, float], None]] = None,
        on_log: Optional[Callable[[str], None]] = None,
    ):
        """
        Args:
            config: WorkerConfig
            model: YOLO model object
            model_lock: Lock cho thread-safe inference
            model_id: ID c·ªßa model ƒëang s·ª≠ d·ª•ng
            on_alert: Callback(camera_id, alert_type, is_active, value)
            on_log: Callback(message)
        """
        self.config = config
        self.model = model
        self.model_lock = model_lock
        self.model_id = model_id
        self.on_alert = on_alert
        self.on_log = on_log
        
        # IDs
        self.camera_id = config.camera_id
        
        # State
        self._status = WorkerStatus.STOPPED
        self._is_running = False
        self._stop_event = threading.Event()
        
        # Video capture
        self._cap: Optional[cv2.VideoCapture] = None
        self._cap_lock = threading.Lock()
        self._video_info: Dict[str, Any] = {"width": 0, "height": 0, "fps": 0}
        
        # ===== ATOMIC FRAME STORAGE (key optimization) =====
        self._display_frame: Optional[np.ndarray] = None
        self._display_frame_lock = threading.Lock()
        
        # Detection queue (separate from display)
        self._detection_queue: queue.Queue = queue.Queue(maxsize=2)
        
        # Latest result
        self._latest_result: Optional[Tuple[np.ndarray, Any, bool, float]] = None
        self._latest_result_lock = threading.Lock()
        
        # Threads
        self._capture_thread: Optional[threading.Thread] = None
        self._detection_thread: Optional[threading.Thread] = None
        
        # Reconnection
        self._reconnect_interval = self.MIN_RECONNECT_INTERVAL
        self._last_reconnect_time = 0.0
        self._rtsp_fail_count = 0
        
        # Statistics
        self._frame_count = 0
        self._detection_count = 0
        self._fps_display = 0.0
        self._detection_fps_display = 0.0
        self._last_fps_time = time.time()
        self._fps_frame_counter = 0
        self._fps_detection_counter = 0
        self._fps_counter_lock = threading.Lock()  # Thread-safe cho FPS counters
        
        # Detection state
        self._person_consecutive_count = 0
        self._person_no_detection_count = 0
        self._coal_consecutive_count = 0
        self._coal_no_blockage_count = 0
        self._last_coal_ratio = 0.0
        
        # Cache ROI scaled ƒë·ªÉ tr√°nh t√≠nh to√°n l·∫°i m·ªói frame
        self._cached_roi_person: Optional[List[Tuple[int, int]]] = None
        self._cached_roi_coal: Optional[List[Tuple[int, int]]] = None
        self._cached_frame_size: Optional[Tuple[int, int]] = None
        
        # Alarm state
        self.person_alarm_active = False
        self.coal_alarm_active = False
        self.last_person_detected = False  # Track person detection state for display
        
        # Class IDs
        self.person_class_id = 0
        self.coal_class_id = 1
        
        # Inference stats manager
        self._stats_manager = get_stats_manager()
        
        # PLC client (m·ªói camera c√≥ PLC ri√™ng)
        self._plc_client: Optional[PLCClient] = None
        self._alarm_manager: Optional[AlarmManager] = None
        
        # Logging
        self._alert_logger: Optional[AlertLogger] = None
        self._image_saver: Optional[ImageSaver] = None
        
        # Initialize PLC v√† logging
        self._init_plc()
        self._init_logging()
    
    # ===== PROPERTIES =====
    
    @property
    def status(self) -> WorkerStatus:
        return self._status
    
    @property
    def is_running(self) -> bool:
        return self._is_running
    
    @property
    def fps_display(self) -> float:
        return self._fps_display
    
    @property
    def detection_fps(self) -> float:
        return self._detection_fps_display
    
    @property
    def last_coal_ratio(self) -> float:
        return self._last_coal_ratio
    
    @property
    def video_info(self) -> Dict[str, Any]:
        return self._video_info
    
    # ===== PUBLIC METHODS =====
    
    def _init_plc(self) -> None:
        """Kh·ªüi t·∫°o PLC client (m·ªói camera c√≥ PLC ri√™ng)"""
        if not self.config.plc_ip:
            return
        
        try:
            self._plc_client = PLCClient(
                ip=self.config.plc_ip,
                rack=self.config.plc_rack,
                slot=self.config.plc_slot,
                on_state_change=lambda state: self._log(f"PLC Cam{self.camera_id}: {state.value}"),
                on_error=lambda msg: self._log(f"PLC Cam{self.camera_id} error: {msg}")
            )
            
            # T·∫°o AlarmConfig
            person_alarm_config = AlarmConfig()
            person_alarm_config.db_number = self.config.plc_db_number
            person_alarm_config.byte_offset = self.config.plc_person_byte
            person_alarm_config.bit_offset = self.config.plc_person_bit
            
            coal_alarm_config = AlarmConfig()
            coal_alarm_config.db_number = self.config.plc_db_number
            coal_alarm_config.byte_offset = self.config.plc_coal_byte
            coal_alarm_config.bit_offset = self.config.plc_coal_bit
            
            # T·∫°o AlarmManager
            self._alarm_manager = AlarmManager(
                plc_client=self._plc_client,
                person_alarm=person_alarm_config,
                coal_alarm=coal_alarm_config,
            )
            
            # K·∫øt n·ªëi PLC
            if self._plc_client.connect():
                self._log(f"‚úÖ Camera {self.camera_id}: ƒê√£ k·∫øt n·ªëi PLC {self.config.plc_ip}")
            else:
                self._log(f"‚ö†Ô∏è Camera {self.camera_id}: Kh√¥ng th·ªÉ k·∫øt n·ªëi PLC")
        except Exception as e:
            self._log(f"‚ùå Camera {self.camera_id}: L·ªói kh·ªüi t·∫°o PLC - {str(e)}")
    
    def _init_logging(self) -> None:
        """Kh·ªüi t·∫°o logging"""
        try:
            camera_id_str = f"camera_{self.camera_id}"
            self._alert_logger = AlertLogger(
                logs_dir=self.config.logs_dir,
                camera_id=camera_id_str,
                camera_ip=self.config.rtsp_url,
                location=self.config.camera_name,
            )
            self._image_saver = ImageSaver(
                artifacts_dir=self.config.artifacts_dir,
                camera_id=camera_id_str,
            )
        except Exception as e:
            self._log(f"‚ùå Camera {self.camera_id}: L·ªói kh·ªüi t·∫°o logging - {str(e)}")
    
    def start(self) -> bool:
        """B·∫Øt ƒë·∫ßu worker"""
        if self._is_running:
            return True
        
        if not self.config.rtsp_url:
            self._log(f"‚ùå Camera {self.camera_id}: Kh√¥ng c√≥ RTSP URL")
            return False
        
        self._is_running = True
        self._stop_event.clear()
        self._status = WorkerStatus.STARTING
        
        # K·∫øt n·ªëi PLC n·∫øu ch∆∞a
        if self._plc_client and not self._plc_client.is_connected:
            self._plc_client.connect()
        
        # Start threads
        self._capture_thread = threading.Thread(
            target=self._capture_loop,
            daemon=True,
            name=f"Capture-Cam{self.camera_id}"
        )
        self._detection_thread = threading.Thread(
            target=self._detection_loop,
            daemon=True,
            name=f"Detect-Cam{self.camera_id}"
        )
        
        self._capture_thread.start()
        self._detection_thread.start()
        
        self._log(f"üîÑ Camera {self.camera_id}: ƒêang k·∫øt n·ªëi...")
        return True
    
    def stop(self) -> None:
        """D·ª´ng worker"""
        self._is_running = False
        self._stop_event.set()
        self._status = WorkerStatus.STOPPED
        
        # Wait for threads
        if self._capture_thread and self._capture_thread.is_alive():
            self._capture_thread.join(timeout=2.0)
        if self._detection_thread and self._detection_thread.is_alive():
            self._detection_thread.join(timeout=2.0)
        
        # Release capture
        with self._cap_lock:
            if self._cap:
                self._cap.release()
                self._cap = None
        
        # Disconnect PLC
        if self._plc_client:
            self._plc_client.disconnect()
        
        # T·ªêI ∆ØU MEMORY: Clear all frames v√† results
        with self._display_frame_lock:
            self._display_frame = None
        with self._latest_result_lock:
            self._latest_result = None
        
        # Clear queues ƒë·ªÉ tr√°nh memory buildup
        while not self._detection_queue.empty():
            try:
                self._detection_queue.get_nowait()
            except:
                break
        
        # Reset state
        self.person_alarm_active = False
        self.coal_alarm_active = False
        self._person_consecutive_count = 0
        self._coal_consecutive_count = 0
        
        # T·ªêI ∆ØU MEMORY: Force cleanup GPU v√† CPU memory
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            gc.collect()  # Force Python garbage collection
        except:
            pass
        
        self._log(f"‚èπÔ∏è Camera {self.camera_id}: ƒê√£ d·ª´ng")
    
    def get_display_frame(self, copy: bool = True) -> Optional[np.ndarray]:
        """L·∫•y frame m·ªõi nh·∫•t cho display (atomic, thread-safe)
        
        Args:
            copy: True ƒë·ªÉ tr·∫£ v·ªÅ copy (an to√†n h∆°n)
            
        Returns:
            Frame ho·∫∑c None
        """
        with self._display_frame_lock:
            if self._display_frame is None:
                return None
            return self._display_frame.copy() if copy else self._display_frame
    
    def get_latest_result(self) -> Optional[Tuple[np.ndarray, Any, bool, float]]:
        """L·∫•y result detection m·ªõi nh·∫•t
        
        Returns:
            (frame, yolo_result, coal_blocked, coal_ratio) ho·∫∑c None
        """
        with self._latest_result_lock:
            return self._latest_result
    
    def clear_result(self) -> None:
        """X√≥a result sau khi ƒë√£ x·ª≠ l√Ω"""
        with self._latest_result_lock:
            self._latest_result = None
    
    def update_fps(self) -> None:
        """C·∫≠p nh·∫≠t FPS (g·ªçi t·ª´ GUI thread) - Thread-safe"""
        current_time = time.time()
        elapsed = current_time - self._last_fps_time
        
        # C·∫≠p nh·∫≠t FPS m·ªói 2 gi√¢y
        if elapsed >= 2.0:
            with self._fps_counter_lock:
                # ƒê·ªçc v√† reset counters (thread-safe)
                frame_count = self._fps_frame_counter
                detection_count = self._fps_detection_counter
                self._fps_frame_counter = 0
                self._fps_detection_counter = 0
            
            # T√≠nh FPS (ch√≠nh x√°c: s·ªë frame / th·ªùi gian)
            self._fps_display = frame_count / elapsed if elapsed > 0 else 0.0
            self._detection_fps_display = detection_count / elapsed if elapsed > 0 else 0.0
            self._last_fps_time = current_time
    
    # ===== PRIVATE METHODS =====
    
    def _log(self, message: str) -> None:
        """Log message qua callback"""
        if self.on_log:
            try:
                self.on_log(message)
            except:
                pass
    
    def _alert(self, alert_type: str, is_active: bool, value: float = 0) -> None:
        """Trigger alert callback"""
        if self.on_alert:
            try:
                self.on_alert(self.camera_id, alert_type, is_active, value)
            except:
                pass
    
    def _connect(self) -> bool:
        """K·∫øt n·ªëi t·ªõi RTSP stream"""
        try:
            with self._cap_lock:
                # Release old
                if self._cap:
                    self._cap.release()
                    self._cap = None
                
                # Open new v·ªõi FFMPEG backend
                self._cap = cv2.VideoCapture(self.config.rtsp_url, cv2.CAP_FFMPEG)
                
                if not self._cap.isOpened():
                    return False
                
                # ===== KEY OPTIMIZATION: Gi·∫£m buffer =====
                self._cap.set(cv2.CAP_PROP_BUFFERSIZE, self.config.buffer_size)
                self._cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'H264'))
                
                # Get video info
                self._video_info = {
                    "width": int(self._cap.get(cv2.CAP_PROP_FRAME_WIDTH) or 1920),
                    "height": int(self._cap.get(cv2.CAP_PROP_FRAME_HEIGHT) or 1080),
                    "fps": float(self._cap.get(cv2.CAP_PROP_FPS) or 25),
                }
            
            self._status = WorkerStatus.RUNNING
            self._rtsp_fail_count = 0
            self._reconnect_interval = self.MIN_RECONNECT_INTERVAL
            self._log(f"‚úÖ Camera {self.camera_id}: ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng")
            return True
            
        except Exception as e:
            self._log(f"‚ùå Camera {self.camera_id}: L·ªói k·∫øt n·ªëi - {str(e)}")
            return False
    
    def _reconnect(self) -> None:
        """Reconnect v·ªõi exponential backoff"""
        current_time = time.time()
        
        # Tr√°nh reconnect qu√° nhanh
        if current_time - self._last_reconnect_time < self._reconnect_interval:
            time.sleep(0.1)
            return
        
        self._last_reconnect_time = current_time
        self._status = WorkerStatus.RECONNECTING
        
        self._log(f"üîÑ Camera {self.camera_id}: ƒêang k·∫øt n·ªëi l·∫°i... (ch·ªù {self._reconnect_interval:.0f}s)")
        
        # Release old
        with self._cap_lock:
            if self._cap:
                self._cap.release()
                self._cap = None
        
        time.sleep(0.3)
        
        if self._connect():
            self._reconnect_interval = self.MIN_RECONNECT_INTERVAL
        else:
            # Exponential backoff
            self._reconnect_interval = min(
                self._reconnect_interval * 1.5,
                self.MAX_RECONNECT_INTERVAL
            )
    
    def _capture_loop(self) -> None:
        """Main capture loop - ch·∫°y trong thread ri√™ng"""
        while not self._stop_event.is_set() and self._is_running:
            # Check/connect (kh√¥ng gi·ªØ lock khi g·ªçi _connect)
            need_connect = False
            with self._cap_lock:
                need_connect = (self._cap is None or not self._cap.isOpened())
            
            if need_connect:
                if not self._connect():
                    time.sleep(self._reconnect_interval)
                    continue
            
            try:
                with self._cap_lock:
                    if self._cap is None:
                        continue
                    
                    # ===== KEY OPTIMIZATION: Grab pattern =====
                    # Skip frame c≈© trong buffer
                    if self.config.enable_grab_pattern:
                        for _ in range(self.MAX_GRAB_COUNT - 1):
                            self._cap.grab()
                    
                    # ƒê·ªçc frame m·ªõi nh·∫•t
                    ret, frame = self._cap.read()
                
                if ret and frame is not None:
                    # Update frame count
                    self._frame_count += 1
                    # TƒÉng FPS counter (thread-safe)
                    with self._fps_counter_lock:
                        self._fps_frame_counter += 1
                    self._rtsp_fail_count = 0
                    
                    if self._status != WorkerStatus.RUNNING:
                        self._status = WorkerStatus.RUNNING
                    
                    # V·∫Ω ROI l√™n frame ngay c·∫£ khi ch∆∞a c√≥ detection (ƒë·ªÉ ROI lu√¥n hi·ªÉn th·ªã)
                    # T·ªëi ∆∞u: cache ROI scaled, ch·ªâ copy frame khi c·∫ßn
                    frame_with_roi = self._draw_roi_on_frame_optimized_cached(frame)
                    
                    # ===== ATOMIC FRAME UPDATE (v·ªõi ROI) =====
                    with self._display_frame_lock:
                        self._display_frame = frame_with_roi
                    
                    # Put to detection queue (kh√¥ng block)
                    try:
                        if self._detection_queue.full():
                            self._detection_queue.get_nowait()
                        self._detection_queue.put_nowait(frame)
                    except:
                        pass
                else:
                    self._rtsp_fail_count += 1
                    if self._rtsp_fail_count >= 3:
                        self._status = WorkerStatus.RECONNECTING
                        self._reconnect()
                        
            except Exception as e:
                self._rtsp_fail_count += 1
                if self._rtsp_fail_count >= 3:
                    self._reconnect()
            
            # FPS limiting
            time.sleep(max(0, 0.01))  # ~100 FPS max capture
    
    def _detection_loop(self) -> None:
        """Detection loop - ch·∫°y trong thread ri√™ng"""
        detection_interval = self.config.detection_interval
        
        while not self._stop_event.is_set() and self._is_running:
            loop_start = time.time()
            
            # T·ªêI ∆ØU MEMORY: L·∫•y frame m·ªõi nh·∫•t t·ª´ queue (skip frames c≈© ƒë·ªÉ tr√°nh memory buildup)
            frame = None
            frames_skipped = 0
            while not self._detection_queue.empty():
                try:
                    old_frame = self._detection_queue.get_nowait()
                    frames_skipped += 1
                    frame = old_frame  # Gi·ªØ frame m·ªõi nh·∫•t
                    # Frames c≈© s·∫Ω ƒë∆∞·ª£c GC t·ª± ƒë·ªông (kh√¥ng c·∫ßn del explicit ƒë·ªÉ tr√°nh overhead)
                except:
                    break
            
            if frame is None:
                time.sleep(0.1)
                continue
            
            try:
                # ===== YOLO INFERENCE v·ªõi timing =====
                inference_start = time.time()
                
                with self.model_lock:
                    # T·ªêI ∆ØU: ƒê·∫£m b·∫£o model ch·∫°y tr√™n GPU n·∫øu c√≥
                    import torch
                    device = 'cuda' if torch.cuda.is_available() else 'cpu'
                    results = self.model.predict(
                        frame,
                        conf=self.config.detection_confidence,
                        verbose=False,
                        task='segment',
                        device=device  # Explicit device ƒë·ªÉ ƒë·∫£m b·∫£o d√πng GPU
                    )
                result = results[0] if results else None
                
                inference_time_ms = (time.time() - inference_start) * 1000
                
                # Log inference time v√† GPU usage (m·ªói 20 l·∫ßn log 1 l·∫ßn ƒë·ªÉ tr√°nh spam)
                if self._detection_count % 20 == 0:
                    gpu_info = ""
                    try:
                        import torch
                        if torch.cuda.is_available():
                            gpu_mem = torch.cuda.memory_allocated() / 1024**2
                            gpu_info = f" | GPU: {gpu_mem:.0f}MB"
                    except:
                        pass
                    self._log(f"üìä Cam {self.camera_id}: Inference {inference_time_ms:.1f}ms on {device.upper()}{gpu_info}")
                
                # Record inference stats
                self._stats_manager.record_inference(
                    camera_id=self.camera_id,
                    inference_time_ms=inference_time_ms,
                    model_id=self.model_id
                )
                
                # V·∫Ω segment l√™n frame n·∫øu c√≥ ph√°t hi·ªán (TR∆Ø·ªöC ƒë·ªÉ c√≥ frame ƒë√∫ng th·ªùi ƒëi·ªÉm khi c·∫£nh b√°o)
                display_frame = self._draw_segments_on_frame(frame.copy(), result)
                
                # Detect coal blockage (c·∫ßn display_frame ƒë·ªÉ l∆∞u ƒë√∫ng frame khi c·∫£nh b√°o)
                coal_blocked, coal_ratio = self._detect_coal_blockage(frame, result, display_frame)
                
                # Detect person (c·∫ßn display_frame ƒë·ªÉ l∆∞u ƒë√∫ng frame khi c·∫£nh b√°o)
                person_detected = self._detect_person(frame, result)
                self.last_person_detected = person_detected
                self._update_person_alarm_state(person_detected, frame, display_frame)
                
                # Update display frame v·ªõi segment
                with self._display_frame_lock:
                    self._display_frame = display_frame
                
                # Store result (c·∫ßn gi·ªØ l·∫°i cho UI/log - KH√îNG release)
                with self._latest_result_lock:
                    self._latest_result = (frame.copy(), result, coal_blocked, coal_ratio)
                
                # T·ªêI ∆ØU MEMORY: Periodic cleanup ƒë·ªÉ tr√°nh memory leak (m·ªói 10 l·∫ßn)
                if self._detection_count % 14 == 0:
                    try:
                        import torch
                        if torch.cuda.is_available():
                            # Clear unused GPU memory (kh√¥ng ·∫£nh h∆∞·ªüng model ƒë√£ cache)
                            torch.cuda.empty_cache()
                        # Force Python garbage collection
                        gc.collect()
                    except:
                        pass
                
                self._detection_count += 1
                # TƒÉng detection FPS counter (thread-safe)
                with self._fps_counter_lock:
                    self._fps_detection_counter += 1
                
            except Exception as e:
                print(f"Camera {self.camera_id} detection error: {e}")
            
            # Rate limiting
            elapsed = time.time() - loop_start
            sleep_time = max(0, detection_interval - elapsed)
            if sleep_time > 0:
                time.sleep(sleep_time)
    
    def _detect_coal_blockage(self, frame: np.ndarray, result: Any, display_frame: np.ndarray = None) -> Tuple[bool, float]:
        """Ph√°t hi·ªán t·∫Øc than"""
        if not self.config.enable_coal:
            return False, 0.0
        
        try:
            h, w = frame.shape[:2]
            roi_coal = self._scale_roi(self.config.roi_coal, w, h)
            
            if not roi_coal:
                return False, 0.0
            
            # Create ROI mask
            roi_mask = np.zeros((h, w), dtype=np.uint8)
            roi_polygon = np.array(roi_coal, dtype=np.int32)
            cv2.fillPoly(roi_mask, [roi_polygon], 255)
            roi_area = cv2.countNonZero(roi_mask)
            
            if roi_area == 0 or result is None or result.masks is None:
                return False, 0.0
            
            # Create coal mask
            coal_mask_total = np.zeros((h, w), dtype=np.uint8)
            
            if result.boxes is not None:
                boxes = result.boxes
                masks = result.masks
                
                for i in range(len(boxes)):
                    cls_id = int(boxes.cls[i])
                    if cls_id == self.coal_class_id and masks is not None and i < len(masks.data):
                        # T·ªêI ∆ØU MEMORY: Move GPU tensor v·ªÅ CPU v√† release GPU reference
                        mask_tensor = masks.data[i]
                        mask_data = mask_tensor.cpu().numpy()  # Move to CPU
                        # Release GPU tensor reference (Python s·∫Ω GC khi out of scope)
                        del mask_tensor
                        
                        mask_resized = cv2.resize(mask_data, (w, h), interpolation=cv2.INTER_NEAREST)
                        mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255
                        coal_mask_total = cv2.bitwise_or(coal_mask_total, mask_binary)
                        
                        # T·ªêI ∆ØU: Release intermediate arrays (s·∫Ω ƒë∆∞·ª£c GC)
                        del mask_data, mask_resized, mask_binary
            
            # Calculate ratio
            intersection = cv2.bitwise_and(coal_mask_total, roi_mask)
            coal_area_in_roi = cv2.countNonZero(intersection)
            coal_ratio = (coal_area_in_roi / roi_area * 100) if roi_area > 0 else 0.0
            
            # T·ªêI ∆ØU MEMORY: Release intermediate arrays (s·∫Ω ƒë∆∞·ª£c GC t·ª± ƒë·ªông)
            del intersection
            # Gi·ªØ l·∫°i coal_mask_total v√† roi_mask ƒë·ªÉ d√πng n·∫øu c·∫ßn, nh∆∞ng s·∫Ω ƒë∆∞·ª£c GC sau khi return
            
            self._last_coal_ratio = coal_ratio
            
            # Logic ƒë·∫øm li√™n ti·∫øp
            if coal_ratio >= self.config.coal_ratio_threshold:
                self._coal_no_blockage_count = 0
                self._coal_consecutive_count += 1
                
                if self._coal_consecutive_count >= self.config.coal_consecutive_threshold:
                    # L·∫ßn ƒë·∫ßu: B·∫≠t alarm v√† g·ª≠i PLC
                    if not self.coal_alarm_active:
                        self.coal_alarm_active = True
                        self._alert("coal", True, coal_ratio)
                        # G·ª≠i PLC ON
                        if self._alarm_manager:
                            self._alarm_manager.set_coal_alarm(True)
                    
                    # M·ªói l·∫ßn ƒë·∫°t threshold ƒë·ªÅu l∆∞u log/·∫£nh (theo y√™u c·∫ßu)
                    if self._alert_logger and self._image_saver:
                        # L∆∞u log text
                        self._alert_logger.log_coal_alert(
                            coal_ratio=coal_ratio,
                            threshold=self.config.coal_ratio_threshold,
                            force=True
                        )
                        # L∆∞u ·∫£nh
                        save_frame = display_frame if display_frame is not None else frame
                        if save_frame is not None:
                            self._image_saver.save_frame_direct(
                                frame=save_frame.copy(),
                                alert_type="coal_alert",
                                force=True
                            )
                    
                    # Reset counter sau khi x·ª≠ l√Ω
                    self._coal_consecutive_count = 0
                    return True, coal_ratio
            else:
                self._coal_no_blockage_count += 1
                if self._coal_no_blockage_count >= self.config.coal_no_blockage_threshold:
                    # Reset c·∫£ 2 counter khi t·∫Øt c·∫£nh b√°o
                    self._coal_consecutive_count = 0
                    if self.coal_alarm_active:
                        self.coal_alarm_active = False
                        self._alert("coal", False, coal_ratio)
                        # T·∫Øt PLC alarm
                        self._handle_coal_alarm(frame, coal_ratio, False)
                    # Reset counter "no blockage" sau khi t·∫Øt c·∫£nh b√°o ƒë·ªÉ logic s·∫°ch s·∫Ω
                    self._coal_no_blockage_count = 0
            
            return False, coal_ratio
            
        except Exception as e:
            print(f"Camera {self.camera_id} coal detection error: {e}")
            return False, 0.0
    
    def _update_person_alarm_state(self, person_detected: bool, frame: np.ndarray, display_frame: np.ndarray = None) -> None:
        """C·∫≠p nh·∫≠t tr·∫°ng th√°i alarm ng∆∞·ªùi"""
        if not self.config.enable_person:
            return
        
        if person_detected:
            self._person_no_detection_count = 0
            self._person_consecutive_count += 1
            
            if self._person_consecutive_count >= self.config.person_consecutive_threshold:
                # L·∫ßn ƒë·∫ßu: B·∫≠t alarm v√† g·ª≠i PLC
                if not self.person_alarm_active:
                    self.person_alarm_active = True
                    self._alert("person", True, 0)
                    # G·ª≠i PLC ON
                    if self._alarm_manager:
                        self._alarm_manager.set_person_alarm(True)
                
                # M·ªói l·∫ßn ƒë·∫°t threshold ƒë·ªÅu l∆∞u log/·∫£nh (theo y√™u c·∫ßu)
                if self._alert_logger and self._image_saver:
                    # L∆∞u log text
                    self._alert_logger.log_person_alert(
                        frames_detected=self._person_consecutive_count,
                        threshold=self.config.person_consecutive_threshold,
                        force=True
                    )
                    # L∆∞u ·∫£nh
                    save_frame = display_frame if display_frame is not None else frame
                    if save_frame is not None:
                        self._image_saver.save_frame_direct(
                            frame=save_frame.copy(),
                            alert_type="person_alert",
                            force=True
                        )
                
                # Reset counter sau khi x·ª≠ l√Ω
                self._person_consecutive_count = 0
        else:
            self._person_no_detection_count += 1
            if self._person_no_detection_count >= self.config.person_no_detection_threshold:
                # Reset c·∫£ 2 counter khi t·∫Øt c·∫£nh b√°o
                self._person_consecutive_count = 0
                if self.person_alarm_active:
                    self.person_alarm_active = False
                    self._alert("person", False, 0)
                    # T·∫Øt PLC alarm
                    self._handle_person_alarm(frame, False)
                # Reset counter "no detection" sau khi t·∫Øt c·∫£nh b√°o ƒë·ªÉ logic s·∫°ch s·∫Ω
                self._person_no_detection_count = 0
    
    def _detect_person(self, frame: np.ndarray, result: Any) -> bool:
        """Ph√°t hi·ªán ng∆∞·ªùi trong ROI"""
        if not self.config.enable_person:
            return False
        
        try:
            h, w = frame.shape[:2]
            roi_person = self._scale_roi(self.config.roi_person, w, h)
            
            if not roi_person or result is None or result.boxes is None:
                return False
            
            # Create ROI mask
            roi_mask = np.zeros((h, w), dtype=np.uint8)
            roi_polygon = np.array(roi_person, dtype=np.int32)
            cv2.fillPoly(roi_mask, [roi_polygon], 255)
            
            boxes = result.boxes
            masks = result.masks
            
            # Check if any person is in ROI
            for i in range(len(boxes)):
                cls_id = int(boxes.cls[i])
                if cls_id == self.person_class_id:
                    if masks is not None and i < len(masks.data):
                        # T·ªêI ∆ØU MEMORY: Move GPU tensor v·ªÅ CPU v√† release GPU reference
                        mask_tensor = masks.data[i]
                        mask_data = mask_tensor.cpu().numpy()  # Move to CPU
                        # Release GPU tensor reference
                        del mask_tensor
                        
                        mask_resized = cv2.resize(mask_data, (w, h), interpolation=cv2.INTER_NEAREST)
                        mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255
                        intersection = cv2.bitwise_and(mask_binary, roi_mask)
                        
                        # Early exit n·∫øu t√¨m th·∫•y (tr√°nh x·ª≠ l√Ω th√™m)
                        person_found = cv2.countNonZero(intersection) > 0
                        
                        # T·ªêI ∆ØU MEMORY: Release intermediate arrays tr∆∞·ªõc khi return
                        del mask_data, mask_resized, mask_binary, intersection
                        
                        if person_found:
                            return True
            
            return False
            
        except Exception as e:
            print(f"Camera {self.camera_id} person detection error: {e}")
            return False
    
    def _draw_segments_on_frame(self, frame: np.ndarray, result: Any) -> np.ndarray:
        """V·∫Ω segment ng∆∞·ªùi v√† than l√™n frame (tham kh·∫£o coal_12_12_v1.py)"""
        if result is None or result.masks is None or result.boxes is None:
            # V·∫´n v·∫Ω ROI ngay c·∫£ khi kh√¥ng c√≥ detection
            return self._draw_roi_on_frame(frame)
        
        h, w = frame.shape[:2]
        display_frame = frame.copy()
        
        boxes = result.boxes
        masks = result.masks
        
        # V·∫Ω segment cho t·ª´ng detection
        for i in range(len(boxes)):
            cls_id = int(boxes.cls[i])
            
            if i >= len(masks.data):
                continue
            
            # L·∫•y bounding box
            x1, y1, x2, y2 = boxes.xyxy[i]
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            conf = float(boxes.conf[i])
            
            # T·ªêI ∆ØU MEMORY: L·∫•y mask v√† release GPU tensor ngay
            mask_tensor = masks.data[i]
            mask_data = mask_tensor.cpu().numpy()  # Move to CPU
            # Release GPU tensor reference
            del mask_tensor
            
            mask_resized = cv2.resize(mask_data, (w, h), interpolation=cv2.INTER_NEAREST)
            mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255
            
            # T·ªêI ∆ØU: Release intermediate arrays ngay sau khi d√πng
            del mask_data, mask_resized
            
            # T√≠nh contour m·ªôt l·∫ßn ƒë·ªÉ d√πng cho c·∫£ bounding box v√† v·∫Ω vi·ªÅn
            contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # M√†u theo class
            if cls_id == self.person_class_id:
                # Ng∆∞·ªùi: v·∫Ω bounding box v√† segment
                color = (0, 255, 0)  # Xanh l√°
                alpha = 0.3
                
                # T√≠nh bounding box t·ª´ mask ƒë·ªÉ ƒë·∫£m b·∫£o kh·ªõp v·ªõi segment
                if contours:
                    # L·∫•y contour l·ªõn nh·∫•t (object ch√≠nh)
                    largest_contour = max(contours, key=cv2.contourArea)
                    # T√≠nh bounding rect t·ª´ mask th·ª±c t·∫ø (ƒë·∫£m b·∫£o kh·ªõp v·ªõi segment)
                    bx, by, bw, bh = cv2.boundingRect(largest_contour)
                    # V·∫Ω bounding box t·ª´ mask
                    cv2.rectangle(display_frame, (bx, by), (bx + bw, by + bh), color, 2)
                    del largest_contour
                else:
                    # Fallback: d√πng bounding box t·ª´ YOLO n·∫øu kh√¥ng t√¨m th·∫•y contour
                    cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
                
            elif cls_id == self.coal_class_id:
                # Than: CH·ªà v·∫Ω segment (kh√¥ng v·∫Ω bounding box)
                color = (0, 0, 255)  # ƒê·ªè
                alpha = 0.3
            else:
                del mask_binary, contours  # Release n·∫øu kh√¥ng d√πng
                continue
            
            # T√¥ m√†u overlay cho segment
            colored_mask = np.zeros_like(display_frame)
            colored_mask[mask_binary > 0] = color
            # Blend segment v·ªõi alpha
            mask_3channel = np.stack([mask_binary, mask_binary, mask_binary], axis=2) / 255.0
            display_frame = (display_frame * (1 - mask_3channel * alpha) + colored_mask * (mask_3channel * alpha)).astype(np.uint8)
            
            # V·∫Ω vi·ªÅn contour cho segment (d√πng contours ƒë√£ t√≠nh ·ªü tr√™n)
            if contours:
                cv2.drawContours(display_frame, contours, -1, color, 2)
            
            # T·ªêI ∆ØU MEMORY: Release intermediate arrays sau khi v·∫Ω xong
            # (Arrays s·∫Ω ƒë∆∞·ª£c GC t·ª± ƒë·ªông khi out of scope)
            del colored_mask, mask_3channel, mask_binary, contours
        
        # V·∫Ω ROI l√™n frame (sau khi v·∫Ω segment)
        display_frame = self._draw_roi_on_frame(display_frame)
        
        return display_frame
    
    def _draw_roi_on_frame_optimized_cached(self, frame: np.ndarray) -> np.ndarray:
        """V·∫Ω ROI l√™n frame (t·ªëi ∆∞u - cache ROI scaled, ch·ªâ copy frame)"""
        h, w = frame.shape[:2]
        current_size = (w, h)
        
        # Ki·ªÉm tra xem c√≥ c·∫ßn t√≠nh l·∫°i ROI kh√¥ng (khi frame size thay ƒë·ªïi)
        if self._cached_frame_size != current_size:
            # T√≠nh l·∫°i v√† cache ROI scaled
            self._cached_roi_person = self._scale_roi(self.config.roi_person, w, h)
            self._cached_roi_coal = self._scale_roi(self.config.roi_coal, w, h)
            self._cached_frame_size = current_size
        
        # Copy frame (c·∫ßn thi·∫øt ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng frame g·ªëc)
        display_frame = frame.copy()
        
        # V·∫Ω ROI ng∆∞·ªùi (m√†u v√†ng) - d√πng cached (kh√¥ng c·∫ßn t√≠nh l·∫°i)
        if self._cached_roi_person and len(self._cached_roi_person) >= 3:
            pts = np.array(self._cached_roi_person, dtype=np.int32)
            cv2.polylines(display_frame, [pts], True, (0, 255, 255), 2)
        
        # V·∫Ω ROI than (m√†u ƒë·ªè) - d√πng cached (kh√¥ng c·∫ßn t√≠nh l·∫°i)
        if self._cached_roi_coal and len(self._cached_roi_coal) >= 3:
            pts = np.array(self._cached_roi_coal, dtype=np.int32)
            cv2.polylines(display_frame, [pts], True, (0, 0, 255), 2)
        
        return display_frame
    
    def _draw_roi_on_frame_optimized(self, frame: np.ndarray) -> np.ndarray:
        """V·∫Ω ROI l√™n frame (copy frame) - d√πng cho detection loop"""
        h, w = frame.shape[:2]
        display_frame = frame.copy()
        
        # Scale ROI theo k√≠ch th∆∞·ªõc frame
        roi_person = self._scale_roi(self.config.roi_person, w, h)
        roi_coal = self._scale_roi(self.config.roi_coal, w, h)
        
        # V·∫Ω ROI ng∆∞·ªùi (m√†u v√†ng)
        if roi_person and len(roi_person) >= 3:
            pts = np.array(roi_person, dtype=np.int32)
            cv2.polylines(display_frame, [pts], True, (0, 255, 255), 2)
        
        # V·∫Ω ROI than (m√†u ƒë·ªè)
        if roi_coal and len(roi_coal) >= 3:
            pts = np.array(roi_coal, dtype=np.int32)
            cv2.polylines(display_frame, [pts], True, (0, 0, 255), 2)
        
        return display_frame
    
    def _draw_roi_on_frame(self, frame: np.ndarray) -> np.ndarray:
        """V·∫Ω ROI ng∆∞·ªùi v√† than l√™n frame (d√πng cho detection loop)"""
        h, w = frame.shape[:2]
        display_frame = frame.copy()
        
        # Scale ROI theo k√≠ch th∆∞·ªõc frame
        roi_person = self._scale_roi(self.config.roi_person, w, h)
        roi_coal = self._scale_roi(self.config.roi_coal, w, h)
        
        # V·∫Ω ROI ng∆∞·ªùi (m√†u v√†ng)
        if roi_person and len(roi_person) >= 3:
            pts = np.array(roi_person, dtype=np.int32)
            cv2.polylines(display_frame, [pts], True, (0, 255, 255), 2)
        
        # V·∫Ω ROI than (m√†u ƒë·ªè)
        if roi_coal and len(roi_coal) >= 3:
            pts = np.array(roi_coal, dtype=np.int32)
            cv2.polylines(display_frame, [pts], True, (0, 0, 255), 2)
        
        return display_frame
    
    def _scale_roi(self, roi_points: List[Tuple[int, int]], 
                   target_w: int, target_h: int) -> List[Tuple[int, int]]:
        """Scale ROI theo k√≠ch th∆∞·ªõc frame"""
        if not roi_points:
            return roi_points
        
        ref_w, ref_h = self.config.reference_resolution
        scale_x = target_w / ref_w
        scale_y = target_h / ref_h
        
        return [(int(x * scale_x), int(y * scale_y)) for (x, y) in roi_points]
    
    def get_stats_dict(self) -> Dict[str, Any]:
        """L·∫•y statistics d·∫°ng dict"""
        return {
            "camera_id": self.camera_id,
            "status": self._status.value,
            "frame_count": self._frame_count,
            "detection_count": self._detection_count,
            "fps_display": round(self._fps_display, 1),
            "detection_fps": round(self._detection_fps_display, 1),
            "coal_ratio": round(self._last_coal_ratio, 1),
            "person_alarm": self.person_alarm_active,
            "coal_alarm": self.coal_alarm_active,
            "video_info": self._video_info,
        }
    
    def _handle_coal_alarm(self, frame: np.ndarray, coal_ratio: float, is_active: bool) -> None:
        """X·ª≠ l√Ω c·∫£nh b√°o than: g·ª≠i PLC v√† l∆∞u log/·∫£nh"""
        try:
            # G·ª≠i PLC
            if self._alarm_manager:
                if is_active:
                    self._alarm_manager.set_coal_alarm(True)
                else:
                    self._alarm_manager.set_coal_alarm(False)
            
            # L∆∞u log v√† ·∫£nh
            if is_active and self._alert_logger and self._image_saver:
                # L∆∞u log text
                self._alert_logger.log_coal_alert(
                    coal_ratio=coal_ratio,
                    threshold=self.config.coal_ratio_threshold,
                    force=True
                )
                
                # L∆∞u ·∫£nh: frame ƒë√£ ƒë∆∞·ª£c truy·ªÅn v√†o (ƒë√£ c√≥ ROI v√† segment t·∫°i ƒë√∫ng th·ªùi ƒëi·ªÉm c·∫£nh b√°o)
                if frame is not None:
                    # L∆∞u frame tr·ª±c ti·∫øp, kh√¥ng v·∫Ω th√™m g√¨ (frame ƒë√£ c√≥ ROI + segment)
                    self._image_saver.save_frame_direct(
                        frame=frame.copy(),  # Copy ƒë·ªÉ an to√†n
                        alert_type="coal_alert",
                        force=True
                    )
        except Exception as e:
            self._log(f"‚ùå Camera {self.camera_id}: L·ªói x·ª≠ l√Ω coal alarm - {str(e)}")
    
    def _handle_person_alarm(self, frame: np.ndarray, is_active: bool) -> None:
        """X·ª≠ l√Ω c·∫£nh b√°o ng∆∞·ªùi: g·ª≠i PLC v√† l∆∞u log/·∫£nh"""
        try:
            # G·ª≠i PLC
            if self._alarm_manager:
                if is_active:
                    self._alarm_manager.set_person_alarm(True)
                else:
                    self._alarm_manager.set_person_alarm(False)
            
            # L∆∞u log v√† ·∫£nh
            if is_active and self._alert_logger and self._image_saver:
                # L∆∞u log text
                self._alert_logger.log_person_alert(
                    frames_detected=self._person_consecutive_count,
                    threshold=self.config.person_consecutive_threshold,
                    force=True
                )
                
                # L∆∞u ·∫£nh: frame ƒë√£ ƒë∆∞·ª£c truy·ªÅn v√†o (ƒë√£ c√≥ ROI v√† segment t·∫°i ƒë√∫ng th·ªùi ƒëi·ªÉm c·∫£nh b√°o)
                if frame is not None:
                    # L∆∞u frame tr·ª±c ti·∫øp, kh√¥ng v·∫Ω th√™m g√¨ (frame ƒë√£ c√≥ ROI + segment)
                    self._image_saver.save_frame_direct(
                        frame=frame.copy(),  # Copy ƒë·ªÉ an to√†n
                        alert_type="person_alert",
                        force=True
                    )
        except Exception as e:
            self._log(f"‚ùå Camera {self.camera_id}: L·ªói x·ª≠ l√Ω person alarm - {str(e)}")

